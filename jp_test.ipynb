{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.fields import TextField, LabelField\n",
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "\n",
    "from allennlp.nn import util as nn_util\n",
    "\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "from allennlp.predictors.sentence_tagger import SentenceTaggerPredictor\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from allennlp.common import JsonDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE=2\n",
    "LR = 3e-4\n",
    "EPOCHS = 2\n",
    "HIDDEN_SZ = 64\n",
    "MAX_SEQ_LEN = 100\n",
    "MAX_VOCAB_SIZE = 100000\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "DATA_ROOT = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReader(DatasetReader):\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer:Callable[[str], List[str]]=lambda x: x.split(),\n",
    "        token_indexers:Dict[str, TokenIndexer]=None,\n",
    "        max_seq_len:Optional[int]=MAX_SEQ_LEN\n",
    "    ) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\":SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def text_to_instance(self, tokens:List[Token], label:int=None) -> Instance:\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"tokens\":sentence_field}\n",
    "        if label is not None:\n",
    "            label_field = LabelField(label, skip_indexing=True)\n",
    "            fields[\"label\"] = label_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    def _read(self, data_path:str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(data_path, header=None, names=[\"tokens\",\"label\"], sep=\"\\t\")\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                [Token(x) for x in self.tokenizer(row[\"tokens\"])],\n",
    "                row[\"label\"]\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexer = SingleIdTokenIndexer()\n",
    "\n",
    "j_t = Tokenizer()\n",
    "def tokenizer(text): \n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)][:MAX_SEQ_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今日', 'は', '良い', '天気', 'です', 'ね', '。']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('今日は良い天気ですね。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MyReader(tokenizer = tokenizer, token_indexers={\"tokens\":token_indexer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 330.21it/s]\n",
      "4it [00:00, 678.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(Path(DATA_ROOT) / \"train_ja.tsv\")\n",
    "val_dataset = reader.read(Path(DATA_ROOT) / \"val_ja.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 読み込み結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<allennlp.data.instance.Instance at 0x7f8f8d5f0e48>,\n",
       " <allennlp.data.instance.Instance at 0x7f8f8ae5eb00>,\n",
       " <allennlp.data.instance.Instance at 0x7f8f8ae5efd0>,\n",
       " <allennlp.data.instance.Instance at 0x7f8f8076c0b8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [あなた, を, が, 好き, です, 。],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer at 0x7f901844edd8>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_dataset[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 6668.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset, max_vocab_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@',\n",
       " 1: '@@UNKNOWN@@',\n",
       " 2: 'が',\n",
       " 3: 'です',\n",
       " 4: '。',\n",
       " 5: '好き',\n",
       " 6: '私',\n",
       " 7: 'は',\n",
       " 8: '嫌い',\n",
       " 9: 'あなた',\n",
       " 10: 'を',\n",
       " 11: 'マイク',\n",
       " 12: 'マキ',\n",
       " 13: 'ボブ'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_index_to_token_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ化と番号ふり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=BATCH_SIZE, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'tokens': tensor([[13,  2,  8,  3,  4,  0],\n",
       "          [ 9, 10,  2,  5,  3,  4]])}, 'label': tensor([0, 1])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(iterator(train_dataset)))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, input_sz:int, nch:int=24) -> None:\n",
    "        super(Attn, self).__init__()\n",
    "        self.input_sz = input_sz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, nch),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(nch,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                encoder_outputs:torch.Tensor # (batch_size, seq_len, hidden_sz(=input_sz))\n",
    "               ):\n",
    "        b_size = encoder_outputs.size(0)\n",
    "        attn_ene = self.main(encoder_outputs.view(-1, self.input_sz)) # (b, s, h) -> (b*s, 1)\n",
    "        return F.softmax(attn_ene.view(b_size, -1), dim=1).unsqueeze(2) # (b*s, 1) -> (b, s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierWithAttn(Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        word_embeddings:TextFieldEmbedder, \n",
    "        encoder:Seq2SeqEncoder, # (batch_size, seq_len) -> (batch_size, seq_len. hidden_sz(*2 if bidirectional)) \n",
    "        vocab:Vocabulary) -> None:\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder \n",
    "        self.attn = Attn(self.encoder.get_output_dim()) # encoder.get_output_dim() = hidden_sz(*2 if bidirectional)\n",
    "        self.main = nn.Linear(self.encoder.get_output_dim(), 1)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, tokens:Dict[str, torch.Tensor], label:torch.Tensor = None) -> Dict[str, torch.Tensor]:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        encoder_outputs = self.encoder(embeddings, mask) # (batch_size, seq_len, hidden_sz)\n",
    "        attns = self.attn(encoder_outputs) # (batch_size, seq_len, 1)\n",
    "        feats = (encoder_outputs * attns).sum(dim=1) # (batch_size, hidden_sz)\n",
    "        logits = self.main(feats).view(-1) # (batch_size, 1) -> (batch_size, )\n",
    "        output = {\"logits\":logits, \"attns\":attns}\n",
    "        \n",
    "        if label is not None:\n",
    "            loss = self.loss(logits, label.float())\n",
    "            output[\"loss\"] = loss\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=MAX_VOCAB_SIZE + 2, embedding_dim=300, padding_index=0)\n",
    "word_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\":token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder: Seq2SeqEncoder = PytorchSeq2SeqWrapper(nn.LSTM(word_embeddings.get_output_dim(),\n",
    "                                                       HIDDEN_SZ, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierWithAttn(word_embeddings, encoder, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "label = batch[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[13,  2,  8,  3,  4,  0],\n",
       "         [ 9, 10,  2,  5,  3,  4]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = get_text_field_mask(tokens)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = word_embeddings(tokens)\n",
    "encoder_outputs = encoder(embeddings, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get_output_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attns = model.attn(encoder_outputs) # (batch_size, seq_len, 1)\n",
    "feats = (encoder_outputs * attns).sum(dim=1) # (batch_size, hidden_sz)\n",
    "logits = model.main(feats) # (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 1]), torch.Size([2, 128]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns.shape, feats.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([0.0153, 0.0156], grad_fn=<ViewBackward>),\n",
       " 'attns': tensor([[[0.1671],\n",
       "          [0.1670],\n",
       "          [0.1668],\n",
       "          [0.1666],\n",
       "          [0.1664],\n",
       "          [0.1661]],\n",
       " \n",
       "         [[0.1670],\n",
       "          [0.1669],\n",
       "          [0.1668],\n",
       "          [0.1667],\n",
       "          [0.1664],\n",
       "          [0.1662]]], grad_fn=<UnsqueezeBackward0>),\n",
       " 'loss': tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "iterator = BucketIterator(batch_size=BATCH_SIZE, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    iterator = iterator,\n",
    "    train_dataset = train_dataset,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    num_epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/site-packages/allennlp/common/util.py\", line 379, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/subprocess.py\", line 438, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
      "loss: 0.6932 ||: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n",
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/site-packages/allennlp/common/util.py\", line 379, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/ubuntu/anaconda3/envs/allennlp2/lib/python3.6/subprocess.py\", line 438, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
      "loss: 0.6926 ||: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 1,\n",
       " 'peak_cpu_memory_MB': 1166.188,\n",
       " 'training_duration': '00:00:01',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 1,\n",
       " 'epoch': 1,\n",
       " 'training_loss': 0.69261634349823,\n",
       " 'training_cpu_memory_MB': 1166.188}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPredictor(Predictor):\n",
    "    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n",
    "        super().__init__(model, dataset_reader)\n",
    "        self._tokenizer = dataset_reader.tokenizer\n",
    "\n",
    "    def predict(self, tokens: str) -> JsonDict:\n",
    "        return self.predict_json({\"tokens\" : tokens})\n",
    "\n",
    "    @overrides\n",
    "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
    "        tokens = json_dict[\"tokens\"]\n",
    "        return self._dataset_reader.text_to_instance([Token(x) for x in self._tokenizer(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = MyPredictor(model, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': 0.020878572016954422,\n",
       " 'attns': [[0.14326539635658264],\n",
       "  [0.14314626157283783],\n",
       "  [0.14300484955310822],\n",
       "  [0.14288753271102905],\n",
       "  [0.14275595545768738],\n",
       "  [0.1425764262676239],\n",
       "  [0.142363503575325]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.predict(\"あなたを愛しています。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_allennlp2)",
   "language": "python",
   "name": "conda_allennlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
